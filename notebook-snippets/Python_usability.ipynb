{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T16:58:55.848457Z",
     "start_time": "2019-07-10T16:58:55.845522Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell #display full output instead of just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1. Python - profile a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define a decorator for a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T14:13:37.105906Z",
     "start_time": "2019-05-22T14:13:37.099806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def profileit(filename):\n",
    "    def inner(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            prof = cProfile.Profile()\n",
    "            retval = prof.runcall(func, *args, **kwargs)\n",
    "            # Note use of name from outer scope\n",
    "            prof.dump_stats(filename)\n",
    "            return retval\n",
    "        return wrapper\n",
    "    return inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Wrap a function with the decorator (it will create a new file for each decorated function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T14:14:41.179789Z",
     "start_time": "2019-05-22T14:13:38.420448Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "@profileit(\"log_example\")\n",
    "def example(a: int, b: int):\n",
    "    for _ in range(int(b)):\n",
    "        for _ in range(int(b/5)):\n",
    "            t = a\n",
    "# You need to run the function\n",
    "example(0, 1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evaluate the function using pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T14:14:41.187943Z",
     "start_time": "2019-05-22T14:14:41.182158Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 22 11:14:41 2019    log_example\n",
      "\n",
      "         2 function calls in 62.755 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1   62.755   62.755   62.755   62.755 <ipython-input-2-7ef09a001284>:1(example)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pstats\n",
    "def show_prof(file):\n",
    "    p = pstats.Stats(file)\n",
    "    p.sort_stats('tottime').print_stats(10)\n",
    "for file in [\"log_example\"]:\n",
    "    show_prof(file)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2. Python - profile line by line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ref: https://nesi.github.io/perf-training/python-scatter/profiling#profiling-python-code-with-line_profiler\n",
    "\n",
    "1. Install `line_profiler`:\n",
    "```bash\n",
    "$ pip install line_profiler\n",
    "```\n",
    "\n",
    "2. Decorate every function you want to profile\n",
    "```python\n",
    "@profile\n",
    "def thing():\n",
    "    size = 100000\n",
    "    [1 for _ in range(size)]\n",
    "```\n",
    "\n",
    "3. Run the script using `kernprof` in the terminal:\n",
    "```bash\n",
    "$ kernprof -l -v script.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 3. Multiple Learners pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4,)\n",
      "Running LR\n",
      "0.5\n",
      "Running KNN\n",
      "0.5\n",
      "Running CART\n",
      "0.5\n",
      "Running NB\n",
      "0.5\n",
      "Running SVM\n",
      "0.5\n",
      "Running AB\n",
      "0.5\n",
      "Running GBM\n",
      "0.5\n",
      "Running RF\n",
      "0.5\n",
      "Running ET\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliano.garcia/miniconda3/envs/mlexp/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/juliano.garcia/miniconda3/envs/mlexp/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/juliano.garcia/miniconda3/envs/mlexp/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/juliano.garcia/miniconda3/envs/mlexp/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import toolz as fp\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "tt_df_train = pd.DataFrame({\n",
    "    \"text\": [\"ola eu sou joao\", \"meu nome Ã© maria\", \"tres tristes tigres para tres tigres felizes\", \"1 2 3 4 arroz com batata\"],\n",
    "    \"target\": [1, 0, 0, 1]\n",
    "})\n",
    "tt_df_test = pd.DataFrame({\n",
    "    \"text\": [\"feliz da vida estou\", \"na cidade triste dos tempos de aurora\"],\n",
    "    \"target\": [1, 0]\n",
    "})\n",
    "tt_text_col = \"text\"\n",
    "tt_target_col = \"target\"\n",
    "new_df = tt_df_train\n",
    "print(new_df[tt_text_col].shape)\n",
    "print(new_df[tt_target_col].shape)\n",
    "\n",
    "@fp.curry\n",
    "def fkl_pipeline(df, clf_obj, clf_name, clf_params, vect_params, text_col, target, prediction_column=\"prediction\"):\n",
    "    vect = TfidfVectorizer(**vect_params)\n",
    "    clf = clf_obj(**clf_params)\n",
    "    vect.fit(df[text_col].values)\n",
    "    sparse_vect = vect.transform(df[text_col].values)\n",
    "    clf.fit(sparse_vect, df[target].values)\n",
    "    def p(new_df):\n",
    "        predict_text_df = new_df[text_col]\n",
    "        predict_sparse_vect = vect.transform(predict_text_df)\n",
    "        col_dict = {prediction_column: clf.predict_proba(predict_sparse_vect)[:, 1]}\n",
    "        return new_df.assign(**col_dict)\n",
    "    options = {\"model\": clf_name,\n",
    "               \"vectorizer\": vect,\n",
    "               \"predict_proba\": lambda x: clf.predict_proba(vect.transform(x))}\n",
    "    return p, p(df), options\n",
    "\n",
    "def build_all_pipelines(vect_params, text_col, target_col):\n",
    "    basedModels = []\n",
    "    basedModels.append(('LR'   , LogisticRegression, {}))\n",
    "    basedModels.append(('KNN'  , KNeighborsClassifier, dict(n_neighbors=2)))\n",
    "    basedModels.append(('CART' , DecisionTreeClassifier, {}))\n",
    "    basedModels.append(('NB'   , MultinomialNB, {}))\n",
    "    basedModels.append(('SVM'  , SVC, dict(probability=True)))\n",
    "    basedModels.append(('AB'   , AdaBoostClassifier, {}))\n",
    "    basedModels.append(('GBM'  , GradientBoostingClassifier, {}))\n",
    "    basedModels.append(('RF'   , RandomForestClassifier, {}))\n",
    "    basedModels.append(('ET'   , ExtraTreesClassifier, {}))\n",
    "    return [{\"pipeline\": fkl_pipeline(clf_obj=model_obj,\n",
    "                         clf_name=model_name,\n",
    "                         clf_params=model_params,\n",
    "                         vect_params=vect_params,\n",
    "                         text_col=text_col,\n",
    "                         target=target_col),\n",
    "             \"model\": model_name} for model_name, model_obj, model_params in basedModels]\n",
    "\n",
    "# Build a specific pipeline\n",
    "pipeline = fkl_pipeline(clf_obj=ExtraTreesClassifier,\n",
    "                        clf_name=\"ET\",\n",
    "                        clf_params={},\n",
    "                        vect_params={},\n",
    "                        text_col=tt_text_col,\n",
    "                        target=tt_target_col)\n",
    "# Build all pipelines\n",
    "all_pipe = build_all_pipelines({}, tt_text_col, tt_target_col)\n",
    "for pdict in all_pipe:\n",
    "    print(f\"Running {pdict['model']}\")\n",
    "    p,new_df, log = pdict[\"pipeline\"](tt_df_train)\n",
    "    y_pred = p(tt_df_test)[\"prediction\"].values\n",
    "    y_test = tt_df_test[tt_target_col].values\n",
    "    print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 5. Size of pickled object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T16:09:41.841964Z",
     "start_time": "2019-07-04T16:09:41.817658Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "/private/var/folders/xt/0cb4dztx1lv244nd3b8p2q1w0000gn/T/tmpp2a_wfki\n",
      "b'total 8\\n0 drwx------    3 juliano.garcia  staff    96B Jul  4 13:09 .\\n0 drwx------@ 377 juliano.garcia  staff    12K Jul  4 13:09 ..\\n8 -rw-r--r--    1 juliano.garcia  staff    21B Jul  4 13:09 thing.pkl\\n'\n",
      "b''\n",
      " Manually calculated (MB): 2.1e-05\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def output_pickle_size(object_to_pickle, name=\"thing\"):\n",
    "    import cloudpickle as cpkl\n",
    "    import tempfile\n",
    "    import os\n",
    "    import subprocess\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    temp_dir_path = tempfile.mkdtemp()\n",
    "    temp_output = f\"{name}.pkl\"\n",
    "    os.chdir(temp_dir_path)\n",
    "    cpkl.dump(object_to_pickle, open(temp_output, \"wb\"))\n",
    "    print(os.getcwd())\n",
    "    p = subprocess.Popen(['ls', '-lsah'], stdout=subprocess.PIPE, \n",
    "                                stderr=subprocess.PIPE)\n",
    "\n",
    "    out, err = p.communicate()\n",
    "    print(out)\n",
    "    print(err)\n",
    "    print(f\" Manually calculated (MB): {os.stat(temp_output).st_size/1e6}\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "output_pickle_size({\"1\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 6. Dotdict notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 7. How to extract Series made of arrays into dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T16:59:21.913900Z",
     "start_time": "2019-07-10T16:59:21.892343Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  before --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.45380715508991054, 0.15805359233102678, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.6370909734281631, 0.8086877621351344, 0.818...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.947924923168174, 0.7319697369006363, 0.0457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.6354436688118528, 0.5626937175669025, 0.392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.939050395044145, 0.042204941416884134, 0.87...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              column\n",
       "0  [0.45380715508991054, 0.15805359233102678, 0.3...\n",
       "1  [0.6370909734281631, 0.8086877621351344, 0.818...\n",
       "2  [0.947924923168174, 0.7319697369006363, 0.0457...\n",
       "3  [0.6354436688118528, 0.5626937175669025, 0.392...\n",
       "4  [0.939050395044145, 0.042204941416884134, 0.87..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  after --- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_extract_0</th>\n",
       "      <th>col_extract_1</th>\n",
       "      <th>col_extract_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453807</td>\n",
       "      <td>0.158054</td>\n",
       "      <td>0.375673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.637091</td>\n",
       "      <td>0.808688</td>\n",
       "      <td>0.818033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947925</td>\n",
       "      <td>0.731970</td>\n",
       "      <td>0.045735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.635444</td>\n",
       "      <td>0.562694</td>\n",
       "      <td>0.392792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.939050</td>\n",
       "      <td>0.042205</td>\n",
       "      <td>0.872930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_extract_0  col_extract_1  col_extract_2\n",
       "0       0.453807       0.158054       0.375673\n",
       "1       0.637091       0.808688       0.818033\n",
       "2       0.947925       0.731970       0.045735\n",
       "3       0.635444       0.562694       0.392792\n",
       "4       0.939050       0.042205       0.872930"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_prefix = \"col_extract_\"\n",
    "example_df = pd.DataFrame({\"column\":[np.random.random((3, )) for _ in range(10)]})\n",
    "print(\"---  before --- \")\n",
    "example_df.head()\n",
    "\n",
    "values_matrix = np.stack(example_df[\"column\"].values)\n",
    "output_df = example_df.assign(**{\n",
    "    col_prefix + str(i): values_matrix[:, i] for i in range(values_matrix.shape[1])\n",
    "}).drop(columns=\"column\")\n",
    "print(\"---  after --- \")\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 8. Recursively traverse all keys of multilevel dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T19:38:55.651623Z",
     "start_time": "2019-07-16T19:38:55.643764Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The base object can be a dict or a list currently\n",
    "def myprint(d, curr_indent=0, max_depth=10):\n",
    "    if curr_indent > max_depth:\n",
    "        return\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(\"\\t\"*curr_indent + str(k))\n",
    "            myprint(v, curr_indent=curr_indent + 1, max_depth=max_depth)\n",
    "    elif isinstance(d, list):\n",
    "        for l in d:\n",
    "            print(\"\")\n",
    "            myprint(l, curr_indent=curr_indent + 1, max_depth=max_depth)\n",
    "    elif isinstance(d, set):\n",
    "        for l in sorted(d):\n",
    "            print(\"\\t\"*curr_indent + str(l))\n",
    "            myprint(l, curr_indent=curr_indent + 1, max_depth=max_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T19:38:56.213591Z",
     "start_time": "2019-07-16T19:38:56.208914Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "\ta1\n",
      "\t\ta11\n",
      "\t\ta12\n",
      "b\n",
      "\tb1\n",
      "\t\tb11\n",
      "\t\tb12\n",
      "\tb2\n",
      "\t\tb21\n",
      "\t\tb22\n"
     ]
    }
   ],
   "source": [
    "multilevel_dict = dict(a=dict(a1=dict(a11=1, a12=2)), b=dict(b1=dict(b11=1, b12=2), b2=dict(b21=1, b22=2)))\n",
    "myprint(multilevel_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 9. Colorize strings in unix shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T17:15:13.023232Z",
     "start_time": "2019-08-04T17:15:13.017240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class colorize():\n",
    "    \"\"\"colorize strings in a bash shell\"\"\"\n",
    "    def red(text):\n",
    "        return f\"\\033[1;91m{text}\\033[39m\"\n",
    "\n",
    "    def green(text):\n",
    "        return f\"\\033[1;92m{text}\\033[39m\"\n",
    "\n",
    "    def yellow(text):\n",
    "        return f\"\\033[1;93m{text}\\033[39m\"\n",
    "\n",
    "    def blue(text):\n",
    "        return f\"\\033[1;94m{text}\\033[39m\"\n",
    "\n",
    "    def magenta(text):\n",
    "        return f\"\\033[1;95m{text}\\033[39m\"\n",
    "\n",
    "    def cyan(text):\n",
    "        return f\"\\033[1;96m{text}\\033[39m\"\n",
    "\n",
    "    def white(text):\n",
    "        return f\"\\033[1;97m{text}\\033[39m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T17:15:25.586272Z",
     "start_time": "2019-08-04T17:15:25.582828Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;91moi\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "print(colorize.red(\"oi\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
